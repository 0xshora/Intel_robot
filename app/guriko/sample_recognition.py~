import cv2
import numpy as np
import sys
from scipy import stats
from sklearn.neural_network import MLPClassifier
from sklearn.externals import joblib

version = cv2.__version__.split(".")
CVversion = int(version[0])
capture = cv2.VideoCapture(0)

# 学習に用いる縮小画像のサイズ
sw = 16
sh = 12

#手の認識パラメータ
hmin = 0
hmax = 20
smin = 50

janken_class =  ['グー', 'チョキ', 'パー']

# 学習済ファイルの確認
if len(sys.argv)==2:
    savefile = sys.argv[1]
    try:
        clf = joblib.load(savefile)
    except IOError:
        print('学習済ファイル{0}を開けません'.format(savefile))
        sys.exit()
else:
    print('使用法: python ml-08-04-recognition.py 学習済ファイル.pkl')
    sys.exit()

def getImageVector(img):
    # 白い領域(ピクセル値が0でない領域)の座標を集める
    nonzero = cv2.findNonZero(img)
    # その領域を囲う四角形の座標と大きさを取得
    xx, yy, ww, hh = cv2.boundingRect(nonzero)
    # 白い領域を含む最小の矩形領域を取得
    img_nonzero = img[yy:yy+hh, xx:xx+ww]
    # 白い領域を(sw, sh)サイズに縮小するための準備
    img_small = np.zeros((sh, sw), dtype=np.uint8)
    # 画像のアスペクト比を保ったまま、白い領域を縮小してimg_smallにコピーする
    if 4*hh < ww*3 and hh > 0:
        htmp = int(sw*hh/ww)
        if htmp>0:
            img_small_tmp = cv2.resize(img_nonzero, (sw, htmp), interpolation=cv2.INTER_LINEAR)
            img_small[int((sh-htmp)/2):int((sh-htmp)/2)+htmp, 0:sw] = img_small_tmp
    elif 4*hh >= ww*3 and ww > 0:
        wtmp = int(sh*ww/hh)
        if wtmp>0:
            img_small_tmp = cv2.resize(img_nonzero, (wtmp, sh), interpolation=cv2.INTER_LINEAR)
            img_small[0:sh, int((sw-wtmp)/2):int((sw-wtmp)/2)+wtmp] = img_small_tmp
    # 0...1の範囲にスケーリングしてからリターンする
    return np.array([img_small.ravel()/255.])

print('認識を開始します')

while(True):
     ret,frame = capture.read()
    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)
    hsv_channels = cv2.split(hsv)
    h_channel = hsv_channels[0]
    s_channel = hsv_channels[1]

    h_binary = cv2.GaussianBlur(h_channel,(5,5),0)
    ret,h_binary = cv2.threshold(h_binary,hmax,255,cv2.THRESH_TOZERO_INV)
    ret,h_binary = cv2.threshold(h_binary,hmin,255,cv2.THRESH_BINARY)

    ret,s_binary = cv2.threshold(s_channel,smin,255,cv2.THRESH_BINARY)
    hs_and = h_binary & s_binary

    if CVversion == 2:
        img_dist, img_label = cv2.distanceTransformWithLabels(255-hs_and, cv2.cv.CV_DIST_L2, 5)
    else:
        img_dist, img_label = cv2.distanceTransformWithLabels(255-hs_and, cv2.DIST_L2, 5)
        img_label = np.uint8(img_label) & hs_and

        img_label_not_zero = img_label[img_label != 0]

        if len(img_label_not_zero) != 0:
            m = stats.mode(img_label_not_zero)[0]
        else:
            m = 0
        hand = np.uint8(img_label == m)*255
        hand_vector = getImageVector(hand)
        result = clf.predict(hand_vector)

        print(janken_class[result[0]])

        cv2.imshow('hand',hand)

        key = cv2.Waitkey(1)
        if key & 0xFF = ord('q'):
            break

capture.release()
cv2.destroyAllWindows()
